#include <cuda_fp16.h>
#include <cuda_runtime.h>
#include <cmath>

// 累加类型模板：half使用float累加，float使用float
template <typename T>
struct AccumulateType {};

template <>
struct AccumulateType<half> {
    using type = float;
};

template <>
struct AccumulateType<float> {
    using type = float;
};

template <typename T>
__global__ void group_norm_kernel(
    T* __restrict__ output,
    const T* __restrict__ input,
    const T* __restrict__ gamma,
    const T* __restrict__ beta,
    int N, int C, int H, int W,
    int num_groups, float epsilon) {
    
    using AccT = typename AccumulateType<T>::type;
    
    const int channels_per_group = C / num_groups;
    const int group_size = channels_per_group * H * W;
    const int group_id = blockIdx.x;
    const int n = group_id / num_groups;
    const int g = group_id % num_groups;
    const int input_start = n * C * H * W + g * channels_per_group * H * W;
    
    // 动态共享内存布局：归约缓冲区 + 均值和标准差倒数
    extern __shared__ char shared_mem[];
    AccT* reduce_buf = reinterpret_cast<AccT*>(shared_mem);
    AccT* mean_ptr = reinterpret_cast<AccT*>(shared_mem);
    AccT* inv_std_ptr = mean_ptr + 1;
    
    // 每个线程计算局部和与平方和
    AccT sum_val = 0;
    AccT sum_sq = 0;
    const int tid = threadIdx.x;
    
    for (int idx = tid; idx < group_size; idx += blockDim.x) {
        const T val = input[input_start + idx];
        const AccT val_acc = static_cast<AccT>(val);
        sum_val += val_acc;
        sum_sq += val_acc * val_acc;
    }
    
    // 归约缓冲区初始化
    reduce_buf[tid] = sum_val;
    reduce_buf[tid + blockDim.x] = sum_sq;
    __syncthreads();
    
    // 块内归约（树形结构）
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            reduce_buf[tid] += reduce_buf[tid + s];
            reduce_buf[tid + blockDim.x] += reduce_buf[tid + blockDim.x + s];
        }
        __syncthreads();
    }
    
    // 计算均值和方差
    if (tid == 0) {
        const AccT total_sum = reduce_buf[0];
        const AccT total_sq = reduce_buf[blockDim.x];
        const AccT mean = total_sum / group_size;
        
        // 方差计算（带数值稳定性保护）
        AccT variance = (total_sq - mean * total_sum) / group_size;
        if (variance < static_cast<AccT>(0)) {
            variance = static_cast<AccT>(0);
        }
        variance += static_cast<AccT>(epsilon);
        
        *mean_ptr = mean;
        *inv_std_ptr = rsqrtf(variance);
    }
    __syncthreads();
    
    // 应用归一化
    const AccT mean_val = *mean_ptr;
    const AccT inv_std_val = *inv_std_ptr;
    const int spatial_size = H * W;
    
    for (int idx = tid; idx < group_size; idx += blockDim.x) {
        const int pos = input_start + idx;
        const T val = input[pos];
        const AccT val_acc = static_cast<AccT>(val);
        
        // 归一化计算
        AccT normalized = (val_acc - mean_val) * inv_std_val;
        
        // 计算通道索引
        const int c_in_group = idx / spatial_size;
        const int c = g * channels_per_group + c_in_group;
        
        // 应用缩放和平移
        normalized = normalized * static_cast<AccT>(gamma[c]) 
                   + static_cast<AccT>(beta[c]);
        
        output[pos] = static_cast<T>(normalized);
    }
}

// 封装函数（float版本）
void GroupNormForwardCUDA(
    float* output, const float* input,
    const float* gamma, const float* beta,
    int N, int C, int H, int W,
    int num_groups, float epsilon) {
    
    if (C % num_groups != 0) {
        printf("Error: Channels must be divisible by num_groups\n");
        return;
    }
    
    const int total_groups = N * num_groups;
    dim3 grid(total_groups);
    dim3 block(256);  // 最佳线程数需根据硬件调整
    
    // 共享内存大小：2 * block.x（归约缓冲区）+ 2（均值/标准差）
    size_t shared_size = (2 * block.x + 2) * sizeof(float);
    
    group_norm_kernel<float><<<grid, block, shared_size>>>(
        output, input, gamma, beta,
        N, C, H, W, num_groups, epsilon
    );
}

// 封装函数（half版本）
void GroupNormForwardHalfCUDA(
    half* output, const half* input,
    const half* gamma, const half* beta,
    int N, int C, int H, int W,
    int num_groups, float epsilon) {
    
    if (C % num_groups != 0) {
        printf("Error: Channels must be divisible by num_groups\n");
        return;
    }
    
    const int total_groups = N * num_groups;
    dim3 grid(total_groups);
    dim3 block(256);
    
    // 共享内存大小：2 * block.x（float缓冲区）+ 2 * sizeof(float)
    size_t shared_size = (2 * block.x + 2) * sizeof(float);
    
    group_norm_kernel<half><<<grid, block, shared_size>>>(
        output, input, gamma, beta,
        N, C, H, W, num_groups, epsilon
    );
}
